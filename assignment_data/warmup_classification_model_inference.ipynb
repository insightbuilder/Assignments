{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb346fe",
   "metadata": {},
   "source": [
    "!pip install rich transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb0c55-0c88-4878-8b7b-23278ce28e83",
   "metadata": {},
   "source": [
    "Task: Sentiment Analysis using SequenceClassification Object\n",
    "Models : distilbert-base-uncased-finetuned-sst-2-english, distilbert-base-uncased\n",
    "\n",
    "Task: Text Classification\n",
    "There are classification variants as below \n",
    "\n",
    "- Nat Lang Inference (Entailment, Contradiction, Neutral)\n",
    "\n",
    "- Question Nat Lang Inference Finding if answer present for given question in the context  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f08653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tform\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.999840259552002}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# default_model = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    " \n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I loved Star Wars so much!\")\n",
    "##  [{'label': 'POSITIVE', 'score': 0.99}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "525ee45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "506d474c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model  # Provides the output for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ac80ec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# try another classification model\n",
    "distilbert = 'distilbert-base-uncased'\n",
    "\n",
    "distilpipe = pipeline('sentiment-analysis',\n",
    "                      model=distilbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2c974589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.5283176302909851}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilpipe(\"This is a best way to get things done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "21cc5f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.5297880172729492}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilpipe(\"This is a worst way to explore the amazon rainforest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "acc385f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets dive into the understanding how pipeline is working\n",
    "# Then think how a similar function can be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94b4de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tform\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "73ce1d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_model = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1bfd2c9-132c-4cd2-b9bc-ce42e6c1b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tokenizer = AutoTokenizer.from_pretrained(default_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cff692f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 2307, 2154, 2651,  102,    0,    0],\n",
       "        [ 101, 2045, 2003, 2061, 2172, 4390, 1999, 2008, 2173,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"This is a great day today\", \"There is so much trouble in that place\"]\n",
    "default_tokens = default_tokenizer(text, return_tensors='pt',\n",
    "                                  padding=True)\n",
    "default_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c304f1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2023, 2003, 1037, 2307, 2154, 2651,  102, 2045, 2003, 2061, 2172,\n",
       "         4390, 1999, 2008, 2173,  102]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tokenizer.encode(text, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "227ba0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"finetuning_task\": \"sst-2\",\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"NEGATIVE\",\n",
       "    \"1\": \"POSITIVE\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"NEGATIVE\": 0,\n",
       "    \"POSITIVE\": 1\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.39.3\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get the dimension of the embedding layer?\n",
    "from transformers import AutoConfig\n",
    "\n",
    "default_config = AutoConfig.from_pretrained(default_model)\n",
    "default_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4eeb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the difference between tokenizer and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c2c3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to visualise the Embedding? \n",
    "# Sentence Transformers models create embeding vectors\n",
    "# while the tokenizer create encoded numbers for the tokens\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model_tformers = \"all-mpnet-base-v2\"\n",
    "embed = SentenceTransformer(model_tformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c32a4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_embedding = embed.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e33e21e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a44c9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "\n",
    "dber_orig_tokenizer = DistilBertTokenizer.from_pretrained(default_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98245d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_original = DistilBertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=default_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a12af76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    classifier_output = distilbert_original(**default_tokens)\n",
    "    classifier_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8a13ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_logits = classifier_output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0cc345e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.1843,  4.5188])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2109a1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_original.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "284f85e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predid = classifier_output.logits[0].argmax().item()\n",
    "distilbert_original.config.id2label[predid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d9f26710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEGATIVE'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predid = classifier_output.logits[1].argmax().item()\n",
    "distilbert_original.config.id2label[predid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab3035-76fb-41bd-bcde-9a6c31c297d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(arg1, arg2, *args, **kwargs):\n",
    "# Now make a function that takes text, along with other \n",
    "# args, and returns a sentiment label\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61899424-60f5-40bb-ac35-d553dcd01869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'ENTAILMENT', 'score': 0.9883741140365601}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli_classifier = pipeline(\"text-classification\",\n",
    "                          model=\"roberta-large-mnli\")\n",
    "nli_output = nli_classifier(\"A soccer game with multiple males playing. Some men are playing a sport.\")\n",
    "nli_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876e49f2-7b0c-4f65-b4e0-a4961036f588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9978110194206238}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\",\n",
    "                      model = \"cross-encoder/qnli-electra-base\")\n",
    "\n",
    "classifier(\"Where is the capital of France?, Paris is the capital of France.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13522fe-47b0-4d4e-ad0e-c657161bd643",
   "metadata": {},
   "source": [
    "https://huggingface.co/transformers/v3.0.2/model_doc/auto.html\n",
    "\n",
    "Provides the intro to AutoModel classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d4392-fe66-4331-9a4b-c7cc39424ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
